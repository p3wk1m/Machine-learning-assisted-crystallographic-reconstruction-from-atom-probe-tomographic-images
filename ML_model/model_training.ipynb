{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaed9b5-e462-44bc-afda-3cf018c52623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools_CNN import *\n",
    "# from tools_Transformer import *\n",
    "# from tools_VAE import *\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e47c8b-9b50-4868-847c-b28f85d2597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592dcdf-aca0-4c5f-af7b-47daa4f228fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "totalnum = 100000\n",
    "testnum = int(totalnum*0.2)\n",
    "import random\n",
    "pics_100_exp=[]\n",
    "\n",
    "turns = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b466578-7d81-46e1-ae9c-9df9fa5cd96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import struct\n",
    "int_size = 4\n",
    "class BinDataset(Sequence):\n",
    "    def __init__(self, file_dir, batch_size, transform=None):\n",
    "        self.file_dir = file_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.file_list = [f for f in os.listdir(file_dir) if f.endswith('.bin')]\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_list) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        files = self.file_list[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X,y= self.load_batch(files)\n",
    "        return X, y\n",
    "\n",
    "    def load_batch(self, files):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(self.file_dir, file_name)\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                combined_data = f.read()\n",
    "            int_size=4\n",
    "            int1_bytes = combined_data[:int_size]\n",
    "            int2_bytes = combined_data[int_size:2 * int_size]\n",
    "            int3_bytes = combined_data[2 * int_size:3 * int_size]\n",
    "            \n",
    "            int1 = struct.unpack('i', int1_bytes)[0]\n",
    "            int2 = struct.unpack('i', int2_bytes)[0]\n",
    "            int3 = struct.unpack('i', int3_bytes)[0]\n",
    "            \n",
    "            y = np.array([int1,int2,int3])+15\n",
    "            compressed_data_bytes = bytes(combined_data[3*int_size:])\n",
    "            compressed_data_bytes = np.unpackbits(np.frombuffer(compressed_data_bytes, dtype=np.uint8))\n",
    "            compressed_data_bytes = compressed_data_bytes.astype(np.float32).reshape((1,64, 64, 64,1))\n",
    "            data.append(compressed_data_bytes)  \n",
    "            labels.append(y)   \n",
    "            \n",
    "        return np.concatenate(data),np.array(labels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf3537-5087-4406-98b3-be664869c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "turn = 17\n",
    "turn = 2\n",
    "file_dir = 'train'+str(turn)\n",
    "batch_size = 256  \n",
    "\n",
    "\n",
    "train_dataset_2 = BinDataset(file_dir, batch_size)\n",
    "\n",
    "file_dir2 = 'test'+str(turn)\n",
    "\n",
    "test_dataset_2 = BinDataset(file_dir2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1ee93-098e-4e55-a871-8fa7abe05f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier()\n",
    "\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "\n",
    "\n",
    "\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "softmax_layer = tf.keras.layers.Softmax()\n",
    "loss_metric = tf.keras.metrics.Mean()\n",
    "loss_metric1 = tf.keras.metrics.Mean()\n",
    "loss_metric2 = tf.keras.metrics.Mean()\n",
    "loss_metric3 = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f9642-292b-4cac-bec8-86b208af04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "alpha = 0.01\n",
    "epochs = 50\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=100e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb920460-cc3e-4ed2-9b63-b4ac7c244fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import r2_score\n",
    "names = list(range(1,2,1))\n",
    "for epoch in range(epochs):\n",
    "    for step, x_batch_train in enumerate(train_dataset_2):\n",
    "        x_batch = x_batch_train[0]\n",
    "        rnd_batch = x_batch_train[1]\n",
    "        plot_slices(8,8,64,64,x_batch[0])\n",
    "        idx_tensor = [[idx for idx in range(31)] for i in range(x_batch.shape[0])]\n",
    "        one_hot_y = to_categorical(rnd_batch, num_classes=31).squeeze()\n",
    "        one_hot_y_list = [one_hot_y[:,0,:],one_hot_y[:,1,:],one_hot_y[:,2,:]]\n",
    "        rnd_batch_T = np.transpose(rnd_batch)\n",
    "\n",
    "        b_tmp = 0.0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y = classifier(x_batch)\n",
    "            a = tf.compat.v1.losses.softmax_cross_entropy(one_hot_y_list, y)\n",
    "            b0 = tf.nn.softmax(y)\n",
    "            b1 = tf.reduce_sum(b0 * idx_tensor, 2) \n",
    "            b = alpha * mse_loss_fn(rnd_batch_T,b1)\n",
    "            b_tmp = mse_loss_fn(rnd_batch_T/30.0,b1/30.0)\n",
    "            loss = a + b\n",
    "\n",
    "        grads = tape.gradient(loss, classifier.trainable_weights)\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, classifier.trainable_weights))\n",
    "        loss_metric(loss)\n",
    "        loss_metric1(a)\n",
    "        loss_metric2(b_tmp)\n",
    "        if (epoch % 1 == 0 and step==0):\n",
    "            print(\"Start of epoch %d\" % (epoch,))\n",
    "            print(\"step %d: mean loss = %.4f ,%.4f ,%.4f\" % (step, loss_metric.result(),loss_metric1.result(),loss_metric2.result()))\n",
    "    for step, x_batch_train in enumerate(test_dataset_2):\n",
    "        x_batch = x_batch_train[0]\n",
    "        rnd_batch = x_batch_train[1]\n",
    "        idx_tensor = [[idx for idx in range(31)] for i in range(x_batch.shape[0])]\n",
    "        one_hot_y = to_categorical(rnd_batch, num_classes=31).squeeze()\n",
    "        one_hot_y_list = [one_hot_y[:,0,:],one_hot_y[:,1,:],one_hot_y[:,2,:]]\n",
    "        rnd_batch_T = np.transpose(rnd_batch)\n",
    "        y = classifier(x_batch)\n",
    "        a = tf.compat.v1.losses.softmax_cross_entropy(one_hot_y_list, y)\n",
    "        b0 = tf.nn.softmax(y)\n",
    "        b1 = tf.reduce_sum(b0 * idx_tensor, 2) \n",
    "        b = alpha * mse_loss_fn(rnd_batch_T,b1)\n",
    "        b_tmp = mse_loss_fn(rnd_batch_T/30.0,b1/30.0)\n",
    "        loss = a + b\n",
    "        loss_metric3(b_tmp)\n",
    "    loss_val.append(loss_metric3.result().numpy())\n",
    "    loss_train.append(loss_metric2.result().numpy())\n",
    "    print('train ',loss_metric2.result().numpy(), ' val ',loss_metric3.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4bed7-293a-46af-8c09-5f48f2e64686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
